{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Run\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.webservice import AksEndpoint\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute\n",
    "from sklearn.linear_model   import LogisticRegression\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.ensemble       import RandomForestClassifier\n",
    "from sklearn.metrics        import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment = Experiment(workspace=ws, name=\"azureml-iris-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data for training\n",
    "iris_df = pd.read_csv('./data/iris.csv')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding (Gender)\n",
    "iris_df['species'] = iris_df.species.map( {'setosa': 0, 'virginica': 1, 'versicolor': 2} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Feature and Target\n",
    "Feature = iris_df.drop(columns=['species'], axis=1)\n",
    "Target  = iris_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Feature, Target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [5, 10, 20, 50, 100]\n",
    "\n",
    "for estimator in estimators:\n",
    "    run = experiment.start_logging()\n",
    "    run.log(\"estimator_value\", estimator)\n",
    "    \n",
    "    # Random Forest classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    run.log('Accuracy', accuracy)\n",
    "    \n",
    "    model_name = \"rf_model_est_\" + str(estimator) + \".pkl\"\n",
    "    filename = \"outputs/\" + model_name\n",
    "    \n",
    "    joblib.dump(value=classifier, filename=f'outputs/rf_model_est_{str(estimator)}.pkl')\n",
    "    \n",
    "    run.upload_file(name=model_name, path_or_stream=filename)\n",
    "    run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run_id: 4cc64b21-a8bc-4457-b52b-90b6c0f181ad\n",
      "Best run_id accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_acc_runid = None\n",
    "best_acc = None\n",
    "\n",
    "best_modeldf = pd.DataFrame()\n",
    "\n",
    "for run in experiment.get_runs():\n",
    "    run_metrics = run.get_metrics()\n",
    "    run_details = run.get_details()\n",
    "#     best_modeldf = best_modeldf.append([run_metrics])\n",
    "#     print(run_details)\n",
    "# Choose best estomator\n",
    "    \n",
    "    # each logged metric becomes a key in this returned dict\n",
    "    try:\n",
    "        run_acc = run_metrics[\"Accuracy\"]\n",
    "        run_id = run_details[\"runId\"]\n",
    "    except:\n",
    "        run_acc = 0\n",
    "        run_id  = 999\n",
    "    \n",
    "    if best_acc is None:\n",
    "        best_acc = run_acc\n",
    "        best_acc_runid = run_id\n",
    "    else:\n",
    "        if run_acc > best_acc:\n",
    "            best_acc = run_acc\n",
    "            best_acc_runid = run_id\n",
    "\n",
    "print(\"Best run_id: \" + best_acc_runid)\n",
    "print(\"Best run_id accuracy: \" + str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['outputs/rf_model_est_10.pkl', 'outputs/rf_model_est_100.pkl', 'outputs/rf_model_est_20.pkl', 'outputs/rf_model_est_5.pkl', 'outputs/rf_model_est_50.pkl', 'rf_model_est_100.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Choose Best Estimator\n",
    "best_run = Run(experiment=experiment, run_id=best_acc_runid)\n",
    "best_run\n",
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_run.download_file(name=\"rf_model_est_100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_iris_model\tsklearn_iris_model:1\t1\n"
     ]
    }
   ],
   "source": [
    "# register model\n",
    "model = run.register_model(model_name='sklearn_iris_model',\n",
    "                           model_path='outputs/rf_model_est_5.pkl')\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'rf_model_est_5.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    predict_map = {0:'setosa', 1:'virginica', 2:'versicolor'}\n",
    "    data = np.array(json.loads(raw_data)['data']).reshape(-1, 1)\n",
    "    # make prediction\n",
    "    y_hat = model.predict(data)\n",
    "    # you can return any data type as long as it is JSON-serializable\n",
    "    return predict_map[y_hat.tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ACI Instance & Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"IRIS\",  \"method\" : \"sklearn\"}, \n",
    "                                               description='Predict IRIS with sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-11-04 09:38:20+00:00 Creating Container Registry if not exists.\n",
      "2021-11-04 09:38:20+00:00 Registering the environment.\n",
      "2021-11-04 09:38:20+00:00 Use the existing image.\n",
      "2021-11-04 09:38:20+00:00 Generating deployment configuration.\n",
      "2021-11-04 09:38:21+00:00 Submitting deployment to compute.\n",
      "2021-11-04 09:38:24+00:00 Checking the status of deployment test-sklearn-iris-ab78..\n",
      "2021-11-04 09:40:10+00:00 Checking the status of inference endpoint test-sklearn-iris-ab78.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 1.03 s, sys: 232 ms, total: 1.26 s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import uuid\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, id='sklearn_iris_model:1') # We can get this from model section\n",
    "\n",
    "\n",
    "myenv = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=\"10\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "service_name = 'test-sklearn-iris-' + str(uuid.uuid4())[:4]\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=service_name, \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://e5f3e3ee-e4f5-476e-b9b8-47825f82e99a.eastus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://e5f3e3ee-e4f5-476e-b9b8-47825f82e99a.eastus2.azurecontainer.io/score\n",
      "label: 1\n",
      "prediction: \"virginica\"\n"
     ]
    }
   ],
   "source": [
    "## Sending Raw HTTPS request\n",
    "import requests\n",
    "\n",
    "# send a random row from the test set to score\n",
    "input_data = \"{\\\"data\\\": [\" + str(list(X_test.iloc[10])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "# for AKS deployment you'd need to the service key in the header as well\n",
    "# api_key = service.get_key()\n",
    "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "#print(\"input data:\", input_data)\n",
    "print(\"label:\", y_test.iloc[10])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    6.5\n",
       "sepal_width     3.2\n",
       "petal_length    5.1\n",
       "petal_width     2.0\n",
       "Name: 110, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": [[6.5, 3.2, 5.1, 2.0]]}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{\\\"data\\\": [\" + str(list(X_test.iloc[10])) + \"]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
